name: 'deepseek_chat_llm'
description: 'deepseek_chat_llm'
model_name: 'deepseek-chat'
temperature: 0.5
max_tokens: 2000
#
# When agentUniverse starts, it will automatically read the `DEEPSEEK_API_KEY` from the environment variables
# and assign its value to api_key during YAML configuration parsing.
# The same logic applies to other parameters with placeholders below, such as organization, api_base, and proxy.
#
api_key: '${DEEPSEEK_API_KEY}'
api_base: 'https://api.deepseek.com/v1'
organization: '${DEEPSEEK_ORGANIZATION}'
proxy: '${DEEPSEEK_PROXY}'
streaming: True
metadata:
  type: 'LLM'
  module: 'agentuniverse.llm.default.deep_seek_openai_style_llm'
  class: 'DefaultDeepSeekLLM'