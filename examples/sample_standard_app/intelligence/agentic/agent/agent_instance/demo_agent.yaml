info:
  #  Please fill in the basic info of your agent. The following is a sample.
  name: 'demo_agent'
  description: 'demo agent'
profile:
  # Please fill in the profile of your agent. The following is a sample.
  prompt_version: demo_agent.cn
  # Please select the LLM configuration for your agent.
  #
  # There are two ways to configure the LLM for your agent:
  #
  # Way 1:
  # Explicitly specify the LLM configuration in the llm_model section:
  # - name (Required): Specify the name of the LLM component
  # - Runtime parameters (Optional): temperature, streaming, max_tokens, etc.
  #   These parameters control the behavior of the LLM during execution.
  #
  # Example:
  #   llm_model:
  #     name: 'demo_customized_llm'
  #   Defined in /intelligence/agentic/llm/custom/demo_customized_llm.yaml
  #
  # Way 2:
  # Omit the llm_model section entirely:
  # - System will automatically look for 'default_llm.toml' in the LLM directory
  # - The default LLM specified in this file will be used to assemble the agent
  #
  # Example default_llm.toml:
  #   [DEFAULT]
  #   default_llm = 'qwen2.5-72b-instruct'
  #
  # Note: The current configuration uses Way 1, as shown below
  llm_model:
    name: 'qwen2.5-72b-instruct'
action:
  # Please select the tools and knowledge base.
  tool:
    # here we use a mock_search_tool to mock a search result
    # you can change to customized search tool
    # e.g. demo_search_tool, to do a real internet search
    # for using demo_search_tool, you need to get either /Google/Bing/search.io search API key
    # and config it into /config/custom_key.toml
    - 'mock_search_tool'
  knowledge:
    # advantage featureï¼Œplease refer to doc
memory:
  name: 'demo_memory'
metadata:
  type: AGENT
  class: DemoAgent
