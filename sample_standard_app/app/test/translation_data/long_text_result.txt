
Rag agent execution result is :
上周，我在美国国会大厦就人工智能和监管问题发表了演讲，该活动吸引了立法界和商界的领袖。我对开源社区在抵御那些可能扼杀创新的监管措施方面取得的进展感到鼓舞。但开源的反对者仍在不断转变他们的论点，最新的担忧焦点是开源对国家安全的影响。我希望我们大家都能继续致力于保护开源！

基于与立法者的对话，我对美国联邦政府在切实把握人工智能风险方面取得的进展感到鼓舞。明确地说，需要有监管措施。但这些措施应针对人工智能应用，而非通用型人工智能技术。尽管如此，正如我之前所写，一些公司急于限制开源，可能是为了保护他们在专有模型上所做的巨额投资价值，并阻止竞争对手。观察他们论点随时间演变的过程颇为引人入胜。

例如，大约12个月前，人工智能安全中心的“关于人工智能风险的声明”警告说，人工智能可能引发人类灭绝的风险，并引发了人们对人工智能接管的担忧。这引起了华盛顿高层领导人的警觉。但许多人工智能领域的专家指出，这种反乌托邦科幻场景在现实中缺乏依据。大约六个月后，当我在美国参议院的人工智能洞察论坛上作证时，立法者们对人工智能接管的担忧已大大减少。随后，开源的反对者转变了策略。他们主要论点转向了AI协助制造生物武器的风险。不久之后，OpenAI和RAND的研究表明，当前的AI并没有显著提高不法分子制造生物武器的能力。对AI辅助生物武器的担忧已有所减少。诚然，不法分子使用生物武器（无论是否借助AI）的可能性仍然是国际社会高度关注的问题。最新阻止开源AI的论点已经转向了国家安全。AI在经济竞争和战争中都有用处，开源AI的反对者认为美国应该确保其对手无法接触到最新的基础模型。虽然我不希望专制政府使用AI，尤其是用于发动不公正的战争，但大型语言模型（LLM）的技术已经公开，如果民主国家限制访问，专制国家将会填补这一空白。当有一天，某个地方的孩子向AI系统询问关于民主、自由媒体的作用或独立司法在维护法治中的功能时，我希望AI能够反映民主价值观，而不是优先考虑专制领导者的目标，比如说，人权。我从华盛顿回来后对我们的进步感到乐观。一年前，立法者似乎有80%的时间在讨论AI的监管措施，而只有20%的时间在讨论投资创新。我很高兴现在更多地讨论投资创新，而不是监管措施。

除了美国联邦政府，全球范围内还有许多其他司法管辖区。不幸的是，支持那些会阻碍AI发展的监管措施的论点仍在不断增加。但我从访问华盛顿和其他国家首都的经历中了解到，与监管机构的对话确实能产生影响。若你有机会与任何层级的监管机构交流，请尽力帮助政府更深入地理解AI。