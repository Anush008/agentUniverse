
Rag agent execution result is :
上周，我在美国国会大厦就人工智能与监管问题发表了演讲，该活动吸引了立法和商界领袖的参与。我对开源社区成功抵御那些可能抑制创新的法规所取得的进展感到鼓舞。但反对开源的人士仍在不断调整他们的论点，最新的担忧焦点在于开源对国家安全可能产生的影响。我希望我们都能继续保护开源！

基于与立法者的交流，我对美国联邦政府在准确评估人工智能风险方面取得的进展感到鼓舞。明确地说，确实需要设置防护措施。然而，这些防护措施应针对具体的人工智能应用，而不是通用的人工智能技术。尽管如此，正如我之前所述，一些公司积极限制开源，可能是为了保护他们在专有模型上的巨额投资，并遏制竞争对手。观察他们的论点随时间的变化，颇具观察价值。

例如，大约12个月前，人工智能安全中心的“人工智能风险声明”警告说，人工智能可能导致人类灭绝，并激起了对人工智能接管的恐惧。这引起了华盛顿领导人的关注。但许多人工智能专家指出，这种反乌托邦的科幻场景缺乏现实基础。大约六个月后，当我在美国参议院的人工智能洞察论坛上作陈述时，立法者不再那么担心人工智能的接管。随后，开源的反对者调整了他们的论点，主要论点转为人工智能可能帮助制造生物武器的风险。不久之后，OpenAI和兰德公司指出，当前的人工智能并未显著增强恶意行为者制造生物武器的能力。因此，对AI辅助生物武器的担忧有所减少。当然，坏人可能使用生物武器（无论是否借助AI）这一可能性仍然是国际上极为关注的话题。最新的反对开放源代码AI的论点已转向国家安全。AI在经济竞争和战争中都具有重要作用，反对开放源代码的人士认为美国应确保其对手无法接触到最新的基础模型。虽然我不希望专制政府使用AI，尤其是用于发动不义之战，但大型语言模型（LLM）的秘密已无法掩盖，如果民主国家限制访问，专制国家将会填补这一空白。将来某日，若有孩子向AI询问关于民主、自由媒体或独立司法在维护法治中的作用，我希望AI能反映民主价值观，而不是偏袒专制领导人的目标，例如忽视人权。我从华盛顿回来时，对我们在AI领域取得的进展感到乐观。一年前，立法者在我看来似乎将80%的时间用于讨论AI的监管措施，而只有20%的时间用于讨论创新投资。我很高兴这一比例已经显著逆转，现在更多的是讨论对创新的投入。

放眼美国联邦政府之外，全球各地有许多不同的司法管辖区。不幸的是，那些支持可能阻碍AI发展的监管规定的论点仍在不断增多。但我从访问华盛顿和其他国家首都的经历中学到，与监管者进行对话确实能够产生积极影响。如果你有机会与任何级别的监管者交谈，我希望你能尽力帮助政府更深入地理解AI。